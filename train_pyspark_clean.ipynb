{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import  SparkContext\n",
    "from pyspark.sql.functions import col, lower\n",
    "from pyspark.sql import SQLContext\n",
    "import re\n",
    "sc = SparkContext('local','test1')\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "dems_df =  sql.read.text(\"dems.txt\")\n",
    "gop_df = sql.read.text(\"gop.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = dems_df.select(\"value\", lit(1).alias(\"label\")).union(gop_df.select(\"value\", lit(0).alias(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|This week @senate...|    1|\n",
      "|Health care profe...|    1|\n",
      "|RT @SeemaNanda: G...|    1|\n",
      "|Republicans keep ...|    1|\n",
      "|RT @SpeakerPelosi...|    1|\n",
      "|While the preside...|    1|\n",
      "|You are not alone...|    1|\n",
      "|RT @DNCWarRoom: W...|    1|\n",
      "|RT @DNCWarRoom: T...|    1|\n",
      "|RT @DNCWarRoom: T...|    1|\n",
      "|LISTEN. TO. HEALT...|    1|\n",
      "|RT @SeemaNanda: B...|    1|\n",
      "|This is a HUGE wi...|    1|\n",
      "|RT @SenSherrodBro...|    1|\n",
      "|RT @WisDems: Make...|    1|\n",
      "|Trump had warning...|    1|\n",
      "|RT @DemConvention...|    1|\n",
      "|Abortion is healt...|    1|\n",
      "|RT @RepLucyMcBath...|    1|\n",
      "|Get counted. Get ...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_df.select(\"*\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,lower,col,trim\n",
    "from pyspark.sql.types import FloatType,StringType,IntegerType\n",
    "def clean_text(text):\n",
    "    text=re.sub(r'@[A-Za-z0-9]+','',text).strip() #remove mentions\n",
    "    text=re.sub(r'#','',text).strip() #removing #symbol\n",
    "    text=re.sub(r'RT[\\s]+','',text).strip()\n",
    "    text=re.sub(r'[?|$|.|!|;|:|&|\"|,|\"|\"|*|-|(|)]','',text).strip()\n",
    "    text=re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)+',\"\",text).strip()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value\n",
    "clean_udf_str=udf(lambda z: clean_text(z), StringType())\n",
    "corpus_df=corpus_df.select(\"label\",clean_udf_str(\"value\").alias(\"value\"))\n",
    "emoji_udf_str=udf(lambda z: remove_emoji(z), StringType())\n",
    "corpus_df=corpus_df.select(\"label\",emoji_udf_str('value').alias('value'))\n",
    "corpus_df=corpus_df.select(trim(lower(col('value'))).alias(\"value\"),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|this week  said w...|    1|\n",
      "|health care profe...|    1|\n",
      "|good to see  sign...|    1|\n",
      "|republicans keep ...|    1|\n",
      "|the congress has ...|    1|\n",
      "|while the preside...|    1|\n",
      "|you are not alone...|    1|\n",
      "|well this is conc...|    1|\n",
      "|trump â€œin the end...|    1|\n",
      "|trump proposed hu...|    1|\n",
      "|listen to health ...|    1|\n",
      "|breaking we  alon...|    1|\n",
      "|this is a huge wi...|    1|\n",
      "|update this is th...|    1|\n",
      "|make sure your vo...|    1|\n",
      "|trump had warning...|    1|\n",
      "|in light of the u...|    1|\n",
      "|abortion is healt...|    1|\n",
      "|why does completi...|    1|\n",
      "|get counted get c...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#After Preprocessing\n",
    "corpus_df.select(\"*\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = corpus_df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StopWordsRemover\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"value\", outputCol=\"words\")\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_cleaned\")\n",
    "vectorizer = CountVectorizer(inputCol=\"words_cleaned\", outputCol=\"features\")\n",
    "cleaning_pipeline = Pipeline(stages = [tokenizer,stop_words_remover,vectorizer])\n",
    "cleaning_pipeline_model = cleaning_pipeline.fit(corpus_df)\n",
    "cleaned_training_df = cleaning_pipeline_model.transform(train_df)\n",
    "cleaned_testing_df = cleaning_pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|               value|label|               words|       words_cleaned|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                    |    1|                  []|                  []|   (58092,[0],[1.0])|\n",
      "|'emergency' - an ...|    1|['emergency', -, ...|['emergency', -, ...|(58092,[18,23,46,...|\n",
      "|'read the transcr...|    1|['read, the, tran...|['read, transcrip...|(58092,[0,2,3,180...|\n",
      "|'s actions on dac...|    1|['s, actions, on,...|['s, actions, dac...|(58092,[1,204,247...|\n",
      "|'s discriminatory...|    1|['s, discriminato...|['s, discriminato...|(58092,[0,4,203,2...|\n",
      "|'s leadership is ...|    1|['s, leadership, ...|['s, leadership, ...|(58092,[0,41,81,1...|\n",
      "|'s role in our na...|    1|['s, role, in, ou...|['s, role, nation...|(58092,[0,51,69,7...|\n",
      "|'s visit to pa is...|    1|['s, visit, to, p...|['s, visit, pa, r...|(58092,[242,247,2...|\n",
      "|'we have to not b...|    1|['we, have, to, n...|['we, afraid, cen...|(58092,[15,30,135...|\n",
      "|- a personal than...|    1|[-, a, personal, ...|[-, personal, tha...|(58092,[0,18,83,2...|\n",
      "|-- out of many we...|    1|[--, out, of, man...|[--, many, one, e...|(58092,[19,28,88,...|\n",
      "|-- the same group...|    1|[--, the, same, g...|[--, group, shell...|(58092,[0,76,85,4...|\n",
      "|-19    3 16      ...|    1|[-19, , , , 3, 16...|[-19, , , , 3, 16...|(58092,[0,320,180...|\n",
      "|-creating good-pa...|    1|[-creating, good-...|[-creating, good-...|(58092,[0,4,49,69...|\n",
      "|-lower prescripti...|    1|[-lower, prescrip...|[-lower, prescrip...|(58092,[0,42,116,...|\n",
      "|1 day of trump he...|    1|[1, day, of, trum...|[1, day, trump, h...|(58092,[2,3,16,18...|\n",
      "|1 in 10 americans...|    1|[1, in, 10, ameri...|[1, 10, americans...|(58092,[0,7,12,25...|\n",
      "|1 in 3 college st...|    1|[1, in, 3, colleg...|[1, 3, college, s...|(58092,[0,20,25,3...|\n",
      "|1 in 3 women expe...|    1|[1, in, 3, women,...|[1, 3, women, exp...|(58092,[35,144,23...|\n",
      "|1 in 3 women worl...|    1|[1, in, 3, women,...|[1, 3, women, wor...|(58092,[0,35,144,...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_training_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "naive_bayes = NaiveBayes(featuresCol=\"features\", labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model = naive_bayes.fit(cleaned_training_df)\n",
    "predictions_df = naive_bayes_model.transform(cleaned_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|   (58092,[0],[1.0])|    1|       0.0|\n",
      "|(58092,[0,12,24,1...|    1|       0.0|\n",
      "|(58092,[0,119,179...|    1|       1.0|\n",
      "|(58092,[18,109,12...|    1|       0.0|\n",
      "|(58092,[10,11,12,...|    1|       1.0|\n",
      "|(58092,[5,9,10,11...|    1|       1.0|\n",
      "|(58092,[4,20,26,2...|    1|       1.0|\n",
      "|(58092,[0,167,194...|    1|       1.0|\n",
      "|(58092,[8,12,15,2...|    1|       1.0|\n",
      "|(58092,[0,1,20,29...|    1|       0.0|\n",
      "|(58092,[0,13,14,4...|    1|       1.0|\n",
      "|(58092,[0,38,138,...|    1|       1.0|\n",
      "|(58092,[4,6,9,22,...|    1|       1.0|\n",
      "|(58092,[0,2,4,31,...|    1|       1.0|\n",
      "|(58092,[5,7,20,24...|    1|       1.0|\n",
      "|(58092,[0,38,55,9...|    1|       1.0|\n",
      "|(58092,[7,25,44,5...|    1|       1.0|\n",
      "|(58092,[10,11,43,...|    1|       1.0|\n",
      "|(58092,[0,23,82,1...|    1|       1.0|\n",
      "|(58092,[4,38,112,...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_df.select(\"features\",\"label\",\"prediction\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8804404824331411"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "eval = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction', metricName = 'accuracy')\n",
    "eval.evaluate(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|   (58092,[0],[1.0])|\n",
      "|(58092,[18,23,46,...|\n",
      "|(58092,[0,2,3,180...|\n",
      "|(58092,[1,204,247...|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_training_df.select(\"features\").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
